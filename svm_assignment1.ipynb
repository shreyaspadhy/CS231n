{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import time\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class linear_svm(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def compute_loss_noloop(self, W, X, y):\n",
    "        delta = 1.0\n",
    "        loss_naive = 0.0\n",
    "        \n",
    "        scores = X.dot(W)\n",
    "        z = np.arange(X.shape[0])\n",
    "\n",
    "        corr_scor = np.reshape(scores[z,y], (scores[z,y].shape[0],1))\n",
    "        corr_scor = np.broadcast_to(corr_scor, (corr_scor.shape[0],W.shape[1]))\n",
    "        #print(scores[ix_(:,y)].shape)\n",
    "        margins = np.maximum(scores - corr_scor + delta,0)\n",
    "        margins[z,y] = 0\n",
    "        \n",
    "        loss_naive += np.sum(margins)\n",
    "        \n",
    "        return loss_naive + np.linalg.norm(W)\n",
    "        \n",
    "    def compute_loss_oneloop(self, W, X, y):\n",
    "        delta = 1.0\n",
    "        loss_naive = 0.0\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            scores = X[i].dot(W)\n",
    "            margins = np.maximum(scores - scores[y[i]] + delta,0)\n",
    "            margins[y[i]] = 0\n",
    "            loss_naive += np.sum(margins)\n",
    "            \n",
    "        return loss_naive + np.linalg.norm(W)\n",
    "    \n",
    "    def compute_loss_twoloops(self, W, X, y):\n",
    "        delta = 1.0\n",
    "        loss_naive = 0.0\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            scores = X[i].dot(W)\n",
    "            \n",
    "            for j in range(len(scores)):\n",
    "                if j != y[i]:\n",
    "                    loss_naive += max(scores[j]-scores[y[i]] + delta, 0)\n",
    "            \n",
    "        return loss_naive + np.linalg.norm(W)\n",
    "        \n",
    "    def num_grad(self, f, W):\n",
    "        h = 0.0001\n",
    "        grad = np.zeros(W.shape)\n",
    "        \n",
    "        it = np.nditer(W, flags=['multi_index'], op_flags=['readwrite'])\n",
    "        \n",
    "        while not it.finished:\n",
    "            ix = it.multi_index\n",
    "            fx = f(W)\n",
    "            old_val = W[ix]\n",
    "            W[ix] += h\n",
    "            fxh = f(W)\n",
    "            W[ix] = old_val\n",
    "            grad[ix] = (fxh-fx)/h\n",
    "            it.iternext()\n",
    "            \n",
    "        return grad\n",
    "    \n",
    "    def loss_function(self, W):\n",
    "        return self.compute_loss_noloop(W, self.X, self.y)\n",
    "    \n",
    "    def svm_loss_naive(self, W, X, y, eps):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        grad = self.num_grad(self.loss_function, W)\n",
    "        return grad, self.compute_loss_oneloop(W, X, y)\n",
    "    \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Training Data:', (50000L, 32L, 32L, 3L))\n",
      "('Training Labels:', (50000L,))\n",
      "('Testing Data:', (10000L, 32L, 32L, 3L))\n",
      "('Testing Labels:', (10000L,))\n"
     ]
    }
   ],
   "source": [
    "cifar_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar_dir)\n",
    "\n",
    "print('Training Data:', X_train.shape)\n",
    "print('Training Labels:', y_train.shape)\n",
    "print('Testing Data:', X_test.shape)\n",
    "print('Testing Labels:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Testing Data:', (1000L, 32L, 32L, 3L))\n",
      "('Testing Labels:', (100L, 32L, 32L, 3L))\n"
     ]
    }
   ],
   "source": [
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "num_test = 1000\n",
    "num_dev = 100\n",
    "\n",
    "#Validation Set\n",
    "X_val = X_train[range(num_training, num_training+num_validation)]\n",
    "y_val = y_train[range(num_training, num_training+num_validation)]\n",
    "\n",
    "#Training Set\n",
    "X_train = X_train[range(num_training)]\n",
    "y_train = y_train[range(num_training)]\n",
    "\n",
    "#Development Set\n",
    "mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "\n",
    "#Testing Set\n",
    "X_test = X_test[range(num_test)]\n",
    "y_test = y_test[range(num_test)]\n",
    "\n",
    "print('Testing Data:', X_val.shape)\n",
    "print('Testing Labels:', X_dev.shape)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],-1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],-1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0],-1))\n",
    "X_dev = np.reshape(X_dev, (X_dev.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_image = np.mean(X_train, axis=0)\n",
    "\n",
    "X_train -= mean_image\n",
    "X_test -= mean_image\n",
    "X_val -= mean_image\n",
    "X_dev -= mean_image\n",
    "\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0],1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0],1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0],1))])\n",
    "X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0],1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((49000L, 3073L), (49000L,))\n",
      "0.0174459601853\n",
      "('one loop takes ', 1.0870001316070557)\n",
      "('Two loops take ', 1.1949999332427979)\n",
      "('No loop takes ', 0.11100006103515625)\n",
      "('Loss = ', 447481.06533266651)\n",
      "('Loss = ', 447481.06533266575)\n",
      "('Loss = ', 447481.06533266732)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "W = np.random.randn(X_train.shape[1], 10)*0.0001\n",
    "\n",
    "print(np.linalg.norm(W))\n",
    "svm = linear_svm()\n",
    "eps = 0.00005\n",
    "\n",
    "start = time.time()\n",
    "loss = svm.compute_loss_oneloop(W, X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"one loop takes \", end - start)\n",
    "loss2 = svm.compute_loss_twoloops(W, X_train, y_train)\n",
    "end2 = time.time()\n",
    "print(\"Two loops take \", end2 - end)\n",
    "loss3 = svm.compute_loss_noloop(W, X_train, y_train)\n",
    "end3 = time.time()\n",
    "print(\"No loop takes \", end3 - end2)\n",
    "\n",
    "\n",
    "print('Loss = ', loss)\n",
    "print('Loss = ', loss2)\n",
    "print('Loss = ', loss3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[ -1.40054719e+03,  -4.56853497e+03,  -8.10130200e+02, ...,\n",
      "          1.82593646e+03,  -1.31919961e+03,  -7.33300231e+03],\n",
      "       [ -1.99766710e+03,  -4.39238481e+03,   5.26135529e+02, ...,\n",
      "          1.01021847e+03,  -2.08165128e+03,  -8.53425906e+03],\n",
      "       [ -4.47951483e+03,  -4.29904701e+03,   1.90521157e+03, ...,\n",
      "          2.01379118e+03,  -4.30200537e+03,  -8.57636688e+03],\n",
      "       ..., \n",
      "       [ -3.56550719e+03,  -5.45989503e+03,  -2.82887353e+02, ...,\n",
      "         -1.45349758e+03,   2.03061878e+03,  -4.75935136e+02],\n",
      "       [ -4.99918812e+03,  -6.37360379e+03,   6.61802965e+02, ...,\n",
      "          2.27613324e+02,   6.47408755e+02,  -7.83983764e+01],\n",
      "       [  1.79975588e+01,  -2.09950813e+01,   8.00214470e+00, ...,\n",
      "          1.10002676e+01,   1.90130896e+01,  -1.39989049e+01]]), 953.70393940650831)\n"
     ]
    }
   ],
   "source": [
    "svm = linear_svm()\n",
    "grad, loss = svm.svm_loss_naive(W, X_dev, y_dev, eps)\n",
    "\n",
    "print(grad, loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
