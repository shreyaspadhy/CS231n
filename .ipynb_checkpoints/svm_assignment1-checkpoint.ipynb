{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import time\n",
    "from __future__ import print_function\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class linear_svm(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def compute_loss_noloop(self, W, X, y):\n",
    "        delta = 1.0\n",
    "        loss_naive = 0.0\n",
    "        \n",
    "        scores = X.dot(W)\n",
    "        z = np.arange(X.shape[0])\n",
    "\n",
    "        corr_scor = np.reshape(scores[z,y], (scores[z,y].shape[0],1))\n",
    "        corr_scor = np.broadcast_to(corr_scor, (corr_scor.shape[0],W.shape[1]))\n",
    "        #print(scores[ix_(:,y)].shape)\n",
    "        margins = np.maximum(scores - corr_scor + delta,0)\n",
    "        margins[z,y] = 0\n",
    "        \n",
    "        loss_naive += np.sum(margins)\n",
    "        \n",
    "        loss_naive /= X.shape[0]\n",
    "        \n",
    "        return loss_naive + 5e1*np.linalg.norm(W)\n",
    "        #return loss_naive\n",
    "        \n",
    "    def compute_loss_oneloop(self, W, X, y):\n",
    "        delta = 1.0\n",
    "        loss_naive = 0.0\n",
    "        \n",
    "        for i in range(len(X)):\n",
    "            scores = X[i].dot(W)\n",
    "            margins = np.maximum(scores - scores[y[i]] + delta,0)\n",
    "            margins[y[i]] = 0\n",
    "            loss_naive += np.sum(margins)\n",
    "            \n",
    "        return loss_naive + np.linalg.norm(W)\n",
    "    \n",
    "    def compute_loss_twoloops(self, W, X, y):\n",
    "        delta = 1.0\n",
    "        loss_naive = 0.0\n",
    "        \n",
    "        for i in range(X.shape[0]):\n",
    "            scores = X[i].dot(W)\n",
    "            \n",
    "            for j in range(len(scores)):\n",
    "                if j != y[i]:\n",
    "                    loss_naive += max(scores[j]-scores[y[i]] + delta, 0)\n",
    "            \n",
    "        return loss_naive + np.linalg.norm(W)\n",
    "        \n",
    "    def num_grad(self, f, W):\n",
    "        h = 0.0001\n",
    "        grad = np.zeros(W.shape)\n",
    "        \n",
    "        it = np.nditer(W, flags=['multi_index'], op_flags=['readwrite'])\n",
    "        \n",
    "        while not it.finished:\n",
    "            ix = it.multi_index\n",
    "            fx = f(W)\n",
    "            old_val = W[ix]\n",
    "            W[ix] += h\n",
    "            fxh = f(W)\n",
    "            W[ix] = old_val\n",
    "            grad[ix] = (fxh-fx)/h\n",
    "            it.iternext()\n",
    "            \n",
    "        return grad\n",
    "    \n",
    "    def loss_function(self, W):\n",
    "        return self.compute_loss_noloop(W, self.X, self.y)\n",
    "    \n",
    "    def svm_loss_naive(self, W, X, y, reg = 0.0):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.reg = reg\n",
    "        grad = self.num_grad(self.loss_function, W)\n",
    "        return grad, self.loss_function(W)\n",
    "    \n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data: (50000L, 32L, 32L, 3L)\n",
      "Training Labels: (50000L,)\n",
      "Testing Data: (10000L, 32L, 32L, 3L)\n",
      "Testing Labels: (10000L,)\n"
     ]
    }
   ],
   "source": [
    "cifar_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar_dir)\n",
    "\n",
    "print('Training Data:', X_train.shape)\n",
    "print('Training Labels:', y_train.shape)\n",
    "print('Testing Data:', X_test.shape)\n",
    "print('Testing Labels:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data: (1000L, 32L, 32L, 3L)\n",
      "Testing Labels: (100L, 32L, 32L, 3L)\n"
     ]
    }
   ],
   "source": [
    "num_training = 49000\n",
    "num_validation = 1000\n",
    "num_test = 1000\n",
    "num_dev = 100\n",
    "\n",
    "#Validation Set\n",
    "X_val = X_train[range(num_training, num_training+num_validation)]\n",
    "y_val = y_train[range(num_training, num_training+num_validation)]\n",
    "\n",
    "#Training Set\n",
    "X_train = X_train[range(num_training)]\n",
    "y_train = y_train[range(num_training)]\n",
    "\n",
    "#Development Set\n",
    "mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "X_dev = X_train[mask]\n",
    "y_dev = y_train[mask]\n",
    "\n",
    "#Testing Set\n",
    "X_test = X_test[range(num_test)]\n",
    "y_test = y_test[range(num_test)]\n",
    "\n",
    "print('Testing Data:', X_val.shape)\n",
    "print('Testing Labels:', X_dev.shape)\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],-1))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],-1))\n",
    "X_val = np.reshape(X_val, (X_val.shape[0],-1))\n",
    "X_dev = np.reshape(X_dev, (X_dev.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean_image = np.mean(X_train, axis=0)\n",
    "\n",
    "X_train -= mean_image\n",
    "X_test -= mean_image\n",
    "X_val -= mean_image\n",
    "X_dev -= mean_image\n",
    "\n",
    "X_train = np.hstack([X_train, np.ones((X_train.shape[0],1))])\n",
    "X_test = np.hstack([X_test, np.ones((X_test.shape[0],1))])\n",
    "X_val = np.hstack([X_val, np.ones((X_val.shape[0],1))])\n",
    "X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0],1))])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000L, 3072L) (49000L,)\n",
      "0.0175661115443\n",
      "one loop takes  1.12800002098\n",
      "Two loops take  1.1779999733\n",
      "No loop takes  0.0019998550415\n",
      "Loss =  536670.128729\n",
      "Loss =  536670.128729\n",
      "Loss =  1.21398249869\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "\n",
    "W = np.random.randn(X_train.shape[1], 10)*0.0001\n",
    "\n",
    "print(np.linalg.norm(W))\n",
    "svm = linear_svm()\n",
    "eps = 0.00005\n",
    "\n",
    "start = time.time()\n",
    "loss = svm.compute_loss_oneloop(W, X_train, y_train)\n",
    "end = time.time()\n",
    "print(\"one loop takes \", end - start)\n",
    "loss2 = svm.compute_loss_twoloops(W, X_train, y_train)\n",
    "end2 = time.time()\n",
    "print(\"Two loops take \", end2 - end)\n",
    "loss3 = svm.compute_loss_noloop(W, X_dev, y_dev)\n",
    "end3 = time.time()\n",
    "print(\"No loop takes \", end3 - end2)\n",
    "\n",
    "\n",
    "print('Loss = ', loss)\n",
    "print('Loss = ', loss2)\n",
    "print('Loss = ', loss3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41153793  0.40585927 -0.26836875 -0.35048368 -0.2880097  -0.56919703\n",
      "  0.21976733 -0.43628064  0.29109493  0.11807523]\n",
      "(3073, 10)\n"
     ]
    }
   ],
   "source": [
    "scores = X_train[400].dot(W)\n",
    "\n",
    "print(scores)\n",
    "print(W.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3073L, 10L) 972.744102654\n"
     ]
    }
   ],
   "source": [
    "svm = linear_svm()\n",
    "grad, loss = svm.svm_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "\n",
    "print(grad.shape, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relative Error :  3.85890683202e-05\n",
      "Relative Error :  2.23883640646e-05\n",
      "Relative Error :  3.61506944835e-05\n",
      "Relative Error :  4.78541491208e-05\n",
      "Relative Error :  4.69173998129e-05\n",
      "Relative Error :  2.12273569824e-05\n",
      "Relative Error :  2.92630077495e-05\n",
      "Relative Error :  0.00124360674857\n",
      "Relative Error :  5.0319031962e-05\n",
      "Relative Error :  1.94472811277e-05\n"
     ]
    }
   ],
   "source": [
    "# do the gradient check once again with regularization turned on\n",
    "# you didn't forget the regularization gradient did you?\n",
    "#grad, loss = svm.svm_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "\n",
    "#f = lambda w: svm.svm_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(svm.loss_function, W, grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49000, 3073)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
